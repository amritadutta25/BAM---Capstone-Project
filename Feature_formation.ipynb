{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "###  The file contains steps to form various technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data - Consumer Discretionary Sector\n",
    " Since our sample is very large, we choose to focus on Consumer Discretionary sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'...\\Russell_universe.csv')\n",
    "df = df[df['Sector'] == 'Consumer_Discretionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies=list(df['Ticker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Simple Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMA Rules：\n",
    "1. **Trend Analysis**\n",
    "<br> The basic rule for trading with the SMA is that a security trading above its SMA is in an uptrend, while a security trading below its SMA is in a downtrend.\n",
    "2. **Golden/Death Cross**\n",
    "<br>A death cross occurs when the 50-day simple moving average crosses below the 200-day moving average. This is considered a bearish signal, that further losses are in store. \n",
    "<br>The golden cross occurs when a short-term moving average breaks above a long-term moving average. Reinforced by high trading volumes, this can signal further gains are in store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(shortterm, longterm):\n",
    "    if len(shortterm)==len(longterm):\n",
    "        temp = np.zeros(len(shortterm))\n",
    "        for i in range(1, len(shortterm)):\n",
    "            temp[i] = 1 if shortterm[i] >= longterm[i] and shortterm[i-1] < longterm[i-1] \\\n",
    "                                   else -1 if shortterm[i] <= longterm[i] and shortterm[i-1] > longterm[i-1] \\\n",
    "                                   else 0\n",
    "    else:\n",
    "        raise ValueError('Lengths do not match')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMA Rules：\n",
    "* Use the same rules that apply to SMA when interpreting WMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BB Band Rules：\n",
    "1. To buy when price is near to the lower band and sell then price is near to the upper band.(When the band is parallel)\n",
    "2. Avoid buying in an downtrend and selling in a uptrend.\n",
    "3. **<font color=#DC143C>Measeure the volability by the wide of range. A narrow range guarantees the movements are going either up or down. (HOW? Is there a threshold? How to define this threshold?)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bollinger_band(close, nbdevup=3, nbdevdn=3,timeperiod=20):\n",
    "    upperBB20, middleBB20, lowerBB20 = talib.BBANDS(close, nbdevup, nbdevdn, timeperiod)\n",
    "    bbp = (close - lowerBB20) / (upperBB20 - lowerBB20)\n",
    "    temp = np.array([1 if x < 0 else -1 if x>1 else 0 for x in bbp])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MA_trend(close, MA_days):\n",
    "     #Moving averages, for example, can be used to identify the overall trend. \n",
    "     #If the price is lower than a moving average, the stock is likely to be in a downtrend, and vice versa for an uptrend.\n",
    "    close_MA = talib.EMA(close, timeperiod=MA_days)\n",
    "    trend = crossover(close, close_MA)\n",
    "    return trend\n",
    "\n",
    "def DX_trend(high, low, close, ADX_days = 25, DMI_days = 14):\n",
    "    #When the +DMI is above the -DMI, prices are moving up \n",
    "    #When the -DMI is above the +DMI, prices are moving down, and ADX measures the strength of the downtrend. \n",
    "    #Many traders will use ADX readings above 25 to suggest that the trend is strong enough for trend-trading strategies. \n",
    "    #Conversely, when ADX is below 25, many will avoid trend-trading strategies.\n",
    "    ADX = talib.ADX(high, close, low, timeperiod = ADX_days)\n",
    "    PMI = talib.PLUS_DI(high, low, close, timeperiod = DMI_days)\n",
    "    NMI = talib.MINUS_DI(high, low, close, timeperiod = DMI_days)\n",
    "    ADX_trend = ADX > 25        # the trend is strong\n",
    "    PMI_trend = PMI > NMI       # +DMI is above the -DMI, prices are moving up,\n",
    "    NMI_trend = PMI < NMI       # -DMI is above the +DMI, prices are moving down\n",
    "    trend = np.where(PMI_trend & ADX_trend, 1, np.where(NMI_trend & ADX_trend > 25, -1, 0)) \n",
    "    return trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. BB squeeze: After a tight **consolidation**, the prices are tempt to make a larger move in either direction, ideally in higher volume. Expanding a volume on a breakout is a sign that traders are expect that price will continue to move in the breakout direction. The **longer** it moves in the narrow band, the more likely it evetually to **penatrate these band and eventually continue on in the direction of breakout**, if this event occurs in the direction of previous established longer-term trend. It significants that a potential explosion in price action is about to accur, in the direction of the candlestick pushing againast the band. The **more vertical, the stronger the potential move.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KELCH(high, low, close, Kel_n):  \n",
    "    KelChM = ((high + low + close) / 3).rolling(Kel_n).mean()\n",
    "    KelChU = ((4 * high - 2 * low + close) / 3).rolling(Kel_n).mean()\n",
    "    KelChD = ((-2 * high + 4 * low + close) / 3).rolling(Kel_n).mean()\n",
    "    return KelChU, KelChM, KelChD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BB squeeze\n",
    "def BB_squeeze(low, high, close, timeperiod, nbdevup=2, nbdevdn=2):\n",
    "    BBU, BBM, BBL = talib.BBANDS(close, timeperiod, nbdevup=2, nbdevdn=2, matype=0)\n",
    "    KelChU, KelChM, KelChD = KELCH(high, low, close, timeperiod)\n",
    "    squeeze = 0\n",
    "    waiting_up = 0\n",
    "    waiting_down = 0\n",
    "    signal = np.zeros(len(high))\n",
    "    for i in range(len(high)):\n",
    "        if BBU[i] < KelChU[i] and BBL[i] > KelChD[i]:    ###### find a squeeze\n",
    "            squeeze = 1\n",
    "            waiting_up = 0\n",
    "            waiting_down = 0\n",
    "        if squeeze == 1:\n",
    "            if BBU[i] > KelChU[i] or BBL[i] < KelChD[i]: \n",
    "                squeeze = 0\n",
    "                #Buy: When a squeeze is formed, wait for the upper Bollinger Band® to cross upward through the upper Keltner Channel, and then wait for the price to break the upper band for a long entry.\n",
    "                #Sell: When a squeeze is formed, wait for the lower Bollinger Band® to cross through the downward lower Keltner Channel, and then wait for the the price to break the lower band for a short entry.\n",
    "                if BBU[i] > KelChU[i]:\n",
    "                    waiting_up = 1\n",
    "                if BBL[i] < KelChD[i]:\n",
    "                    waiting_down = 1\n",
    "        if waiting_up == 1 and close[i] > BBU[i] and close[i-1] < BBU[i-1]:\n",
    "            signal[i] = 1\n",
    "            waiting_up = 0\n",
    "        if waiting_down == 1 and close[i] < BBL[i] and close[i-1] > BBL[i-1]:\n",
    "            signal[i] = -1\n",
    "            waiting_down = 0\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMA Rules：\n",
    "* Use the same rules that apply to SMA when interpreting WMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMA Rules：\n",
    "1. Use the same rules that apply to SMA when interpreting WMA\n",
    "2. **<font color=#DC143C>DEMA can be used in a variety of indicators in which the logic is based on a moving average.(e.g. MACD, TRIX) (WHEN?)</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KAMA Rules：\n",
    " real = KAMA(close, timeperiod=30)\n",
    "1. A cross above or below KAMA indicates directional changes in prices\n",
    "2. Combine signals and techniques. Chartists can use a longer-term KAMA to define the bigger trend and a shorter-term KAMA for trading signals. \n",
    "<br>AND [KAMA(10,5,30) >  Daily SMA(50,KAMA(10,5,30))] AND [Daily Close crosses KAMA(10,2,30)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KAMA_combine(close, KAMA_n=30, SMA_n=50):\n",
    "    KAMA = talib.KAMA(close, timeperiod = KAMA_n)\n",
    "    SMA_KAMA = talib.SMA(KAMA, timeperiod = SMA_n)\n",
    "    \n",
    "    # Chartists can use a longer-term KAMA to define the bigger trend and a shorter-term KAMA for trading signals.\n",
    "    up_trend = KAMA > SMA_KAMA\n",
    "    down_trend = KAMA < SMA_KAMA\n",
    "    \n",
    "    # A cross above or below KAMA indicates directional changes in prices\n",
    "    signal = np.zeros(len(close))\n",
    "    up_cross = np.array([True if x==1 else False for x in crossover(close, KAMA)])\n",
    "    down_cross = np.array([True if x==-1 else False for x in crossover(close, KAMA)])\n",
    "    \n",
    "    signal = np.where(up_cross & up_trend, 1, \n",
    "                      np.where(down_cross & down_trend, -1, 0))\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAVP Rules：\n",
    " real = MAVP(close, periods, minperiod=2, maxperiod=30, matype=0)\n",
    "* **<font color=#DC143C>Require periods, which we don't know.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIDPOINT Rules:\n",
    "real = MIDPOINT(close, timeperiod=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIDPRICE Rules：\n",
    "real = MIDPRICE(high, low, timeperiod=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAR Rules：\n",
    "real = SAR(high, low, acceleration=0, maximum=0)\n",
    "1. The basic use of the Parabolic SAR is to buy when the dots move below the price bars (signaling an uptrend) and sell/short-sell when the dots move above the price bars (signaling a downtrend).\n",
    "2. It is better to analyze the price action of the day to determine whether the trend (if there is one) is up or down. Another indicator, such as a moving average or trendlines, can also be used to establish the overall trend direction. If there is a trend, only take trade signals in the direction of the overall trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sar(high, low, close, ADX_days = 25, DMI_days = 14):\n",
    "    trend = DX_trend(high, low, close, ADX_days, DMI_days)\n",
    "    sar = talib.SAR(high, low, acceleration=0, maximum=0)\n",
    "    sar_signal = crossover(close, sar)\n",
    "    signal =  np.array([1 if i==2 else -1 if i==-2 else 0 for i in [z+y for (z,y) in zip(sar_signal, trend)]])\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMA Rules：\n",
    "real = TEMA(close, timeperiod=30)\n",
    "1. TEMA only works on a strong trend.So we can use ADX to help to decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEMA(high, low, close, TEMA_days = 30, ADX_days = 25, DMI_days = 14):\n",
    "    trend = DX_trend(high, low, close, ADX_days, DMI_days)\n",
    "    TEMA = talib.TEMA(close, timeperiod = TEMA_days)\n",
    "    TEMA_signal = crossover(close, TEMA)\n",
    "    signal =  np.array([1 if i==2 else -1 if i==-2 else 0 for i in [z+y for (z,y) in zip(TEMA_signal, trend)]])\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AD line rules:\n",
    "real = AD(high, low, close, volume)\n",
    "1. If the slope of the A/D line is up and the market is trending upward, then the market is said to be healthy.Conversely, if the indexes are continuing to move lower and the A/D line has turned upwards, called bullish divergence, it may be an indication that the sellers are losing their conviction. If the A/D line and the markets are both trending lower together, there is a greater chance that declining prices will continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADline(high, low, close, volume, ADX_days = 25, DMI_days = 14, MA_days = 50):\n",
    "    trend = DX_trend(high, low, close, ADX_days, DMI_days)  # this is the trend of stock price movement\n",
    "    \n",
    "    AD = talib.AD(high, low, close, volume)\n",
    "    AD_trend = MA_trend(AD, MA_days)   # this is trend of OBV movement    \n",
    "    \n",
    "    signal =  np.array([1 if i==2 else -1 if i==-2 else 0 for i in [z+y for (z,y) in zip(AD_trend, trend*(-1))]])\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBV rules:\n",
    "real = OBV(close, volume)\n",
    "1. If the price is going up and the volumn is going down, people are losing confidence in this stock. This is a signal of price decline.\n",
    "2. If the price is going down and the volumns is going up, there will be a reverse in price, which is buy pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OBV(high, low, close, volume, ADX_days = 25, DMI_days = 14, MA_days = 50):\n",
    "    trend = DX_trend(high, low, close, ADX_days, DMI_days)  # this is the trend of stock price movement\n",
    "    \n",
    "    OBV = talib.OBV(close, volume) \n",
    "    OBV_trend = MA_trend(OBV, MA_days)   # this is trend of OBV movement    \n",
    "    \n",
    "    signal =  np.array([1 if i==2 else -1 if i==-2 else 0 for i in [z+y for (z,y) in zip(OBV_trend, trend*(-1))]])\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATR rules:\n",
    "real = ATR(high, low, close, timeperiod=14)\n",
    "1. **Exit Sign**: whenever price closes more than one ATR below the most recent close, a significant change in the nature of the market has occurred. Closing a long position becomes a safe bet, because the stock is likely to enter a trading range or reverse direction at this point.\n",
    "2. Whenever price closes more than an ATR above the most recent close, a change in volatility has occurred. Taking a long position is betting that the stock will follow through in the upward direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATR(high, low, close, ATR_days=14, ADX_days = 25, DMI_days = 14):\n",
    "    trend = DX_trend(high, low, close, ADX_days, DMI_days)  # this is the trend of stock price movement\n",
    "    \n",
    "    ATR =  talib.ATR(high, low, close, timeperiod = ATR_days)\n",
    "\n",
    "    signal = np.zeros(len(high))\n",
    "    for i in range(1, len(close)):\n",
    "        if close[i]-close[i-1] >= ATR[i]:\n",
    "            if trend[i] == 1:\n",
    "                signal[i] = 1\n",
    "            elif trend[i] == -1:\n",
    "                signal[i] = -1\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilbert Transform(HT) Rules\n",
    "inphase, quadrature = HT_PHASOR(close)\n",
    "* BUY - Place Buy position when Blue (InPhase) line crosses above Red (Quadrature) line below the zero level.\n",
    "* SELL - Place Sell position when Blue (InPhase) line crosses below Red (Quadrature) line above the zero level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HT(close):\n",
    "    inphase, quadrature = talib.HT_PHASOR(close)\n",
    "    signal = crossover(inphase, quadrature)\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chande Momentum Oscillator (CMO) Rules\n",
    "real = CMO(close, timeperiod=14)\n",
    "* The oscillator generates a bullish signal when it crosses above the moving average and a bearish signal when it drops below the moving average.\n",
    "* The oscillator can be used as a confirmation signal when it crosses above or below the 0 line. For example, if the 50-day moving average crosses above the 200-day moving average (golden cross), a buy signal is confirmed when the Chande momentum oscillator crosses above 0, predicting prices are headed higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmo(close, cmo_period, ma_period):\n",
    "    res = np.zeros(len(close))\n",
    "    CMO = np.array(talib.CMO(close, timeperiod=cmo_period))\n",
    "    MA = np.array(talib.MA(close, timeperiod = ma_period))\n",
    "    \n",
    "    res = crossover(CMO,MA)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACD Rules\n",
    "1. MACD crossing above zero is considered bullish, while crossing below zero is bearish. Secondly, when MACD turns up from below zero it is considered bullish. When it turns down from above zero it is considered bearish.\n",
    "2. When the MACD line crosses from below to above the signal line, the indicator is considered bullish. The further below the zero line the stronger the signal.\n",
    "3. When the MACD line crosses from above to below the signal line, the indicator is considered bearish. The further above the zero line the stronger the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd(close,fastp,slowp,signalp):\n",
    "    macd, macd_signal, macdhist = np.array(talib.MACD(close, fastperiod=fastp, slowperiod=slowp, signalperiod=signalp))\n",
    "    \n",
    "    res = crossover(macd,macd_signal)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADX rules : \n",
    "The traditional setting for the ADX indicator is 14 time periods, but analysts have commonly used the ADX with settings as low as 7 or as high as 30. Lower settings will make the average directional index respond more quickly to price movement but tend to generate more false signals. Higher settings will minimize false signals but make the average directional index a more lagging indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APO ( Absolute Price Oscillator):\n",
    "1. APO crossing above zero is considered bullish, while crossing below zero is bearish.\n",
    "2. A positive indicator value indicates an upward movement, while negative readings signal a downward trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apo(close,fastp,slowp):\n",
    "    apo_ = np.array(talib.APO(close, fastperiod=fastp, slowperiod=slowp, matype=0))\n",
    "    res = np.zeros(len(close))\n",
    "    for i in range(1,len(apo_)):\n",
    "        if (apo_[i-1] <= 0) and (apo_[i] >0):\n",
    "            res[i] = 1                            #buy\n",
    "        else (apo_[i-1] >= 0) and (apo_[i] <0):\n",
    "            res[i] = -1                          #sell\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AROON\n",
    "When the oscillator moves above the zero line it means the Aroon Up is crossing above the Aroon Down. This means the price has made a high more recently than a low. That could be a sign that an uptrend is starting.\n",
    "\n",
    "https://www.investopedia.com/terms/a/aroonoscillator.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aroon (high,low,timep=14):\n",
    "    aroondown,aroonup = np.array(talib.AROON(df['High'], df['Low'], timeperiod=timep))\n",
    "    aroonosc = np.zeros(len(high))\n",
    "    aroonosc = aroonup - aroondown    # aroon oscillator\n",
    "                                 \n",
    "    res = np.zeros(len(high))\n",
    "    for i in range(1,len(aroonosc)):\n",
    "        if aroonosc[i-1] <= 0 and aroonosc[i] >0:\n",
    "            res[i] = 1\n",
    "        elif aroonosc[i-1] >=0 and aroonosc[i] <0:\n",
    "            res[i] = -1 \n",
    "                                 \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC\n",
    "Positive values indicate upward buying pressure or momentum, while negative values below zero indicate selling pressure or downward momentum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(close, timep= 10):\n",
    "    roc_ =np.array( talib.ROC(close, timeperiod=timep))\n",
    "    res = np.zeros(len(close))\n",
    "    \n",
    "    for i in range(1,len(close)):\n",
    "        if (roc_[i-1] <= 0) and (roc_[i] >0):\n",
    "            res[i] = 1\n",
    "        elif (roc_[i-1] >= 0) and (roc_[i] <0):\n",
    "            res[i] = -1 \n",
    "                                 \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Merge Simple Rules of All Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = list()\n",
    "null_companies = list()\n",
    "for company in companies:\n",
    "    try:\n",
    "        # Get the data from one company\n",
    "        company = company.replace('/',' ')\n",
    "        file='C:/Users/Administrator/Documents/balyansy/companies/'+company+'.csv'\n",
    "        df=pd.read_csv(file, header=5).drop(0)\n",
    "        df = df.dropna(how='any')   # the dates might not be consecutive\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df['Dates']=pd.to_datetime(df['Dates'])\n",
    "\n",
    "        ########### Simple rules ##################\n",
    "        #------------SMA rules-------------------\n",
    "        df['SMA14'] = crossover(df['PX_LAST'], talib.SMA(df['PX_LAST'], timeperiod=15))\n",
    "        df['SMA50'] = crossover(df['PX_LAST'], talib.SMA(df['PX_LAST'], timeperiod=50))\n",
    "        df['SMA200'] = crossover(df['PX_LAST'], talib.SMA(df['PX_LAST'], timeperiod=200))\n",
    "\n",
    "        df['SMA5-10'] = crossover(talib.SMA(df['PX_LAST'], timeperiod=5), talib.SMA(df['PX_LAST'], timeperiod=10))\n",
    "        df['SMA50-200'] = crossover(talib.SMA(df['PX_LAST'], timeperiod=50), talib.SMA(df['PX_LAST'], timeperiod=200))\n",
    "\n",
    "        #------------WMA rules-------------------\n",
    "        df['WMA14'] = crossover(df['PX_LAST'], talib.WMA(df['PX_LAST'], timeperiod=15))\n",
    "        df['WMA50'] = crossover(df['PX_LAST'], talib.WMA(df['PX_LAST'], timeperiod=50))\n",
    "        df['WMA200'] = crossover(df['PX_LAST'], talib.WMA(df['PX_LAST'], timeperiod=200))\n",
    "\n",
    "        df['WMA5-10'] = crossover(talib.WMA(df['PX_LAST'], timeperiod=5), talib.WMA(df['PX_LAST'], timeperiod=10))\n",
    "        df['WMA50-200'] = crossover(talib.WMA(df['PX_LAST'], timeperiod=50), talib.WMA(df['PX_LAST'], timeperiod=200))\n",
    "\n",
    "        #------------WMA rules-------------------\n",
    "        df['WMA14'] = crossover(df['PX_LAST'], talib.WMA(df['PX_LAST'], timeperiod=15))\n",
    "        df['WMA50'] = crossover(df['PX_LAST'], talib.WMA(df['PX_LAST'], timeperiod=50))\n",
    "        df['WMA200'] = crossover(df['PX_LAST'], talib.WMA(df['PX_LAST'], timeperiod=200))\n",
    "\n",
    "        df['WMA5-10'] = crossover(talib.WMA(df['PX_LAST'], timeperiod=5), talib.WMA(df['PX_LAST'], timeperiod=10))\n",
    "        df['WMA50-200'] = crossover(talib.WMA(df['PX_LAST'], timeperiod=50), talib.WMA(df['PX_LAST'], timeperiod=200))\n",
    "\n",
    "        #------------EMA rules-------------------\n",
    "        df['EMA14'] = crossover(df['PX_LAST'], talib.EMA(df['PX_LAST'], timeperiod=15))\n",
    "        df['EMA50'] = crossover(df['PX_LAST'], talib.EMA(df['PX_LAST'], timeperiod=50))\n",
    "        df['EMA200'] = crossover(df['PX_LAST'], talib.EMA(df['PX_LAST'], timeperiod=200))\n",
    "\n",
    "        df['EMA5-10'] = crossover(talib.EMA(df['PX_LAST'], timeperiod=5), talib.EMA(df['PX_LAST'], timeperiod=10))\n",
    "        df['EMA50-200'] = crossover(talib.EMA(df['PX_LAST'], timeperiod=50), talib.EMA(df['PX_LAST'], timeperiod=200))\n",
    "\n",
    "        #------------DEMA rules---------------------\n",
    "        df['DEMA14'] = crossover(df['PX_LAST'], talib.DEMA(df['PX_LAST'], timeperiod=15))\n",
    "        df['DEMA50'] = crossover(df['PX_LAST'], talib.DEMA(df['PX_LAST'], timeperiod=50))\n",
    "        df['DEMA200'] = crossover(df['PX_LAST'], talib.DEMA(df['PX_LAST'], timeperiod=200))\n",
    "\n",
    "        df['DEMA5-10'] = crossover(talib.DEMA(df['PX_LAST'], timeperiod=5), talib.DEMA(df['PX_LAST'], timeperiod=10))\n",
    "        df['DEMA50-200'] = crossover(talib.DEMA(df['PX_LAST'], timeperiod=50), talib.DEMA(df['PX_LAST'], timeperiod=200))    \n",
    "\n",
    "        #-----------BB band rules---------------------\n",
    "        df['BB_crossover'] = bollinger_band(df['PX_LAST'], nbdevup=3, nbdevdn=3,timeperiod=20)\n",
    "        df['BB_squeeze'] = BB_squeeze(df['PX_LOW'], df['PX_HIGH'], df['PX_LAST'], timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "\n",
    "        #------------KAMA rules------------------------\n",
    "        df['KAMA_crossover'] = KAMA_combine(df['PX_LAST'], KAMA_n=30, SMA_n=50)\n",
    "\n",
    "        #----------- SAR rules -------------------------\n",
    "        df['SAR_crossover'] = sar(df['PX_HIGH'], df['PX_LOW'], df['PX_LAST'], ADX_days = 25, DMI_days = 14)\n",
    "\n",
    "        #------------ TEMA rules ------------------------\n",
    "        df['TEMA_crossover'] = TEMA(df['PX_HIGH'], df['PX_LOW'], df['PX_LAST'], TEMA_days = 30, ADX_days = 25, DMI_days = 14)\n",
    "\n",
    "        #------------ AD line rules ---------------------\n",
    "        df['OBV_divergence'] = OBV(df['PX_HIGH'], df['PX_LOW'], df['PX_LAST'], df['PX_VOLUME'], ADX_days = 25, DMI_days = 14, MA_days = 50)\n",
    "\n",
    "        #------------ ATR rules --------------------------\n",
    "        df['ATR_close'] = ATR(df['PX_HIGH'], df['PX_LOW'], df['PX_LAST'], ATR_days=14, ADX_days = 25, DMI_days = 14)\n",
    "\n",
    "        #------------ HT Rules ---------------------------\n",
    "        df['HT_crossover'] = HT(df['PX_LAST'])\n",
    "        \n",
    "        #------------ CMO Rules --------------------------\n",
    "        df['CMO_crossover'] = cmo(df['PX_LAST'], cmo_period = 25, ma_period = 50)\n",
    "        \n",
    "        #------------ MACD Rules --------------------------\n",
    "        df['MACD_12_29_9'], df['MACD_signal_12_29_9'], df['MACD_hist_12_29_9'] = macd(df['PX_LAST'], fastp = 12, slowp = 29,signalp = 9)\n",
    "        df['MACD_5_35_5'], df['MACD_signal_5_35_5'], df['MACD_hist_5_35_5'] = macd(df['PX_LAST'], fastp = 5, slowp = 35,signalp = 5)\n",
    "        \n",
    "        #------------ APO Rules --------------------------\n",
    "        df['apo_'] = talib.APO(df['PX_LAST'], fastperiod=14, slowperiod=30, matype=0)\n",
    "        df['apo_'] = talib.APO(df['PX_LAST'], fastperiod=16, slowperiod=35, matype=0)\n",
    "        \n",
    "        #------------ AROON Rules --------------------------\n",
    "        df['aroondown'],df['aroonup']  = talib.AROON(df['PX_HIGH'], df['PX_LOW'], timeperiod=14)\n",
    "        \n",
    "        #------------ ROC Rules --------------------------\n",
    "        df['ROC'] = roc(df['PX_LAST'], timeperiod=10)\n",
    "        \n",
    "        #------------ STOCH Rules --------------------------\n",
    "        df['slowk'], df['slowd'] = talib.STOCH(df['PX_HIGH'], df['PX_LOW'], df['PX_LAST'], fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "        df['slowk'], df['slowd'] = talib.STOCH(df['PX_HIGH'], df['PX_LOW'], df['PX_LAST'], fastk_period=10, slowk_period=6, slowk_matype=0, slowd_period=5, slowd_matype=0)\n",
    "        df['slowk'], df['slowd'] = talib.STOCH(df['PX_HIGH'], df['PX_LOW'], df['PX_LAST'], fastk_period=15, slowk_period=9, slowk_matype=0, slowd_period=7, slowd_matype=0)\n",
    "        #-----------------------Return Rate-----------------------------\n",
    "        periods = [3,5,10]   # unit = day\n",
    "        thresholds = [0.03, 0.05, 0.10]\n",
    "        for i in periods:\n",
    "            period = i\n",
    "            df['return'+str(period)] = df['PX_LAST'].pct_change(periods = period)\n",
    "        for i in range(len(periods)):\n",
    "            df['signal'+str(periods[i])] = np.where(df['return'+str(periods[i])] > thresholds[i], \n",
    "                                                    1 ,\n",
    "                                                   np.where(df['return'+str(periods[i])] < -thresholds[i],-1,0)\n",
    "                                                   )\n",
    "        #Output all indicators of this company\n",
    "        df=df.dropna(how='any')\n",
    "        df.to_csv('C:/Users/Administrator/Documents/balyansy/indicators/indicator_'+company+'.csv')\n",
    "\n",
    "        # concanate the data from all companies\n",
    "        all_df.append(df)\n",
    "    except:\n",
    "        null_companies.append(company)\n",
    "    \n",
    "data_set = pd.concat(all_df)\n",
    "data_set.to_csv('C:/Users/Administrator/Documents/balyansy/all_companies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Complex Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2-way Rules: combine two simple rules\n",
    "* 3-way Rules: combine three simple rules\n",
    "### Combining rules:\n",
    "1. For combining multiple signals into a final buy/sell decision, we assign a\n",
    "larger weight to trade signals (buy or sell) than to hold signals.\n",
    "2. In case of multiple trade signals, we employ majority voting for deriving the\n",
    "final outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Dates</th>\n",
       "      <th>PX_VOLUME</th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>PX_LOW</th>\n",
       "      <th>PX_HIGH</th>\n",
       "      <th>PX_OPEN</th>\n",
       "      <th>SMA14</th>\n",
       "      <th>SMA50</th>\n",
       "      <th>SMA200</th>\n",
       "      <th>...</th>\n",
       "      <th>TEMA_crossover</th>\n",
       "      <th>OBV_divergence</th>\n",
       "      <th>ATR_close</th>\n",
       "      <th>HT_crossover</th>\n",
       "      <th>return3</th>\n",
       "      <th>return5</th>\n",
       "      <th>return10</th>\n",
       "      <th>signal3</th>\n",
       "      <th>signal5</th>\n",
       "      <th>signal10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>4633800.0</td>\n",
       "      <td>44.2233</td>\n",
       "      <td>44.2051</td>\n",
       "      <td>46.1017</td>\n",
       "      <td>46.1017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028446</td>\n",
       "      <td>-0.028446</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>5152200.0</td>\n",
       "      <td>43.4574</td>\n",
       "      <td>43.4392</td>\n",
       "      <td>45.1534</td>\n",
       "      <td>44.7886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.066221</td>\n",
       "      <td>-0.040273</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2000-01-20</td>\n",
       "      <td>9081000.0</td>\n",
       "      <td>44.4786</td>\n",
       "      <td>43.3297</td>\n",
       "      <td>45.1169</td>\n",
       "      <td>43.8404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044279</td>\n",
       "      <td>-0.022837</td>\n",
       "      <td>0.013716</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2000-01-21</td>\n",
       "      <td>4981200.0</td>\n",
       "      <td>44.2598</td>\n",
       "      <td>44.0410</td>\n",
       "      <td>44.8616</td>\n",
       "      <td>44.6428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>-0.048980</td>\n",
       "      <td>-0.004512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>7797300.0</td>\n",
       "      <td>44.1504</td>\n",
       "      <td>43.9862</td>\n",
       "      <td>45.9558</td>\n",
       "      <td>45.0075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015947</td>\n",
       "      <td>-0.051331</td>\n",
       "      <td>-0.021027</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Dates  PX_VOLUME  PX_LAST   PX_LOW  PX_HIGH  PX_OPEN  \\\n",
       "0          10  2000-01-18  4633800.0  44.2233  44.2051  46.1017  46.1017   \n",
       "1          11  2000-01-19  5152200.0  43.4574  43.4392  45.1534  44.7886   \n",
       "2          12  2000-01-20  9081000.0  44.4786  43.3297  45.1169  43.8404   \n",
       "3          13  2000-01-21  4981200.0  44.2598  44.0410  44.8616  44.6428   \n",
       "4          14  2000-01-24  7797300.0  44.1504  43.9862  45.9558  45.0075   \n",
       "\n",
       "   SMA14  SMA50  SMA200  ...  TEMA_crossover  OBV_divergence  ATR_close  \\\n",
       "0    0.0    0.0     0.0  ...               0               0        0.0   \n",
       "1    0.0    0.0     0.0  ...               0               0        0.0   \n",
       "2    0.0    0.0     0.0  ...               0               0        0.0   \n",
       "3    0.0    0.0     0.0  ...               0               0        0.0   \n",
       "4    0.0    0.0     0.0  ...               0               0        0.0   \n",
       "\n",
       "   HT_crossover   return3   return5  return10  signal3  signal5  signal10  \n",
       "0           0.0 -0.028446 -0.028446  0.001651        0        0         0  \n",
       "1           0.0 -0.066221 -0.040273  0.011460       -1        0         0  \n",
       "2           0.0 -0.044279 -0.022837  0.013716       -1        0         0  \n",
       "3           0.0  0.000825 -0.048980 -0.004512        0        0         0  \n",
       "4           0.0  0.015947 -0.051331 -0.021027        0       -1         0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Administrator\\Documents\\balyansy\\all_companies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct 2-way complex rules\n",
    "# For combining multiple signals into a final buy/sell decision, we assign a larger weight to trade signals (buy or sell) than to hold signals.\n",
    "# When combining buy and sell signal, our decision is hold\n",
    "columns =  [x for x in list(df.columns) if x not in ['Unnamed: 0','Dates', 'PX_VOLUME','PX_LAST','PX_LOW','PX_HIGH','PX_OPEN',\n",
    "                                                              'return3','return5','return10', 'signal3', 'signal5', 'signal10']]\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i+1, len(columns)):\n",
    "        df[columns[i] + '_' + columns[j]] = np.array([1 if x+y>0 else -1 if x+y<0 else 0 for (x, y) in zip(df[columns[i]], df[columns[j]])])\n",
    "\n",
    "# construct 3-way complex rules\n",
    "# For combining multiple signals into a final buy/sell decision, we assign a larger weight to trade signals (buy or sell) than to hold signals.\n",
    "# In case of multiple trade signals, we employ majority voting for deriving the final outcome\n",
    "# When combining buy and sell signal, our decision is hold\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i+1, len(columns)):\n",
    "        for k in range(j+1, len(columns)):\n",
    "            df[columns[i] + '_' + columns[j] + '_' + columns[k]] = np.array([1 if x+y+z>0 else -1 if x+y+z<0 else 0 for (x, y, z) in zip(df[columns[i]], df[columns[j]], df[columns[k]])])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Dates', 'PX_VOLUME', 'PX_LAST', 'PX_LOW', 'PX_HIGH',\n",
       "       'PX_OPEN', 'SMA14', 'SMA50', 'SMA200',\n",
       "       ...\n",
       "       'EMA200_EMA5-10', 'EMA200_EMA50-200', 'EMA200_DEMA14', 'EMA200_DEMA50',\n",
       "       'EMA200_DEMA200', 'EMA200_DEMA5-10', 'EMA200_DEMA50-200',\n",
       "       'EMA200_BB_crossover', 'EMA200_BB_squeeze', 'EMA200_KAMA_crossover'],\n",
       "      dtype='object', length=333)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_rules.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build train and test samples\n",
    "train set (70%), test set (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# romove non_rule columns\n",
    "for column in ['Unnamed: 0','Dates', 'PX_VOLUME','PX_LAST','PX_LOW','PX_HIGH','PX_OPEN']:\n",
    "    del df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.3)\n",
    "\n",
    "#---------------Training Set---------------------------\n",
    "x_train = train.iloc[0:,0:60]\n",
    "y_train = train[[60]]\n",
    "\n",
    "#--------------- Test Set------------------------------\n",
    "x_test = test.iloc[0:,0:60]T\n",
    "y_test = test[[60]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "<li>Build many decision trees from the data set\n",
    "<li>Let them \"vote\" on how to classify inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generally speaking, n_estimators is too small, which is easy to underfit. If n_estimators is too large, the amount of calculation will be too large, and after n_estimators reaches a certain number, increasing the model gain obtained by n_estimators will be small, so generally choose a moderate value. The default is 100.\n",
    "# That is, whether to use samples outside the bag to evaluate the quality of the model. The default is False. Personal recommendation is set to True, because the out-of-bag score reflects the generalization ability of a model after fitting.\n",
    "# max_depth： Because our sample size is large, we need to increase limit the depth of the decision tree （10-100）\n",
    "# min_samples_split(default: 2): Because our sample size is large, we need to increase the minimum size of sample to be splited\n",
    "# min_samples_leaf(default: 1)： Because our sample size is large, we need to increase the minimum size of a leaf node \n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100, oob_score = True, max_depth = 10, min_samples_split = 8, min_samples_leaf = 4)\n",
    "model.fit(x_train,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accuracy</h3>\n",
    "<li>The \"score\" function returns the accuracy of the model (percentage correctly classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ad8743ef54fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcfm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcfm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(x_test)\n",
    "cfm = confusion_matrix(np.ravel(y_test),y_pred)\n",
    "cfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature importance</h3>\n",
    "<li>Since ensemble methods are picking different features in different trees, they can provide us with an estimate of feature importance\n",
    "<li>For each feature, the model calculates by how much entropy decreases (net across levels) by selecting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)),indices)\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finding the best ensemble</h3>\n",
    "<li>Using a gridsearch, we can run the random forest classifier on various parameter combinations\n",
    "<li>And then use the classifier with the best accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "     'n_estimators':(10, 30, 50), #the number of trees\n",
    "     'max_depth':(4, 8, 10, 15),   # 15 can cause overfitting\n",
    "     'min_samples_split': (2, 4, 8, 10, 16),   \n",
    "     'min_samples_leaf': (4, 8, 12, 16)\n",
    "}\n",
    "\n",
    "model = GridSearchCV(RandomForestClassifier(),parameters,cv=3,iid=False)\n",
    "model.fit(x_train, np.ravel(y_train))\n",
    "model.best_score_, model.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
